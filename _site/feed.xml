<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">The many shades of data</title>
<generator uri="https://github.com/jekyll/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="/feed.xml" />
<link rel="alternate" type="text/html" href="" />
<updated>2015-09-02T16:00:25+01:00</updated>
<id>/</id>
<author>
  <name>Anton Sviridov</name>
  <uri>/</uri>
  <email>keynmol@gmail.com</email>
</author>


  

<entry>
  <title type="html"><![CDATA[Visualising timeseries: stocks data and global trends]]></title>
  <link rel="alternate" type="text/html" href="/dataviz/visualising-real-world-timeseries/" />
  <id>/dataviz/visualising-real-world-timeseries</id>
  <published>2015-06-10T00:00:00+01:00</published>
  <updated>2015-06-10T00:00:00+01:00</updated>
  <author>
    <name>Anton Sviridov</name>
    <uri></uri>
    <email>keynmol@gmail.com</email>
  </author>
  <content type="html">
    &lt;section id=&quot;table-of-contents&quot; class=&quot;toc&quot;&gt;
  &lt;header&gt;
    &lt;h3&gt;&lt;i class=&quot;fa fa-book&quot;&gt;&lt;/i&gt; Overview&lt;/h3&gt;
  &lt;/header&gt;
&lt;div id=&quot;drawer&quot;&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot; id=&quot;markdown-toc-introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#getting-ftse-100-stocks&quot; id=&quot;markdown-toc-getting-ftse-100-stocks&quot;&gt;Getting FTSE 100 stocks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#getting-quandl-data-for-stocks&quot; id=&quot;markdown-toc-getting-quandl-data-for-stocks&quot;&gt;Getting Quandl data for stocks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#first-bad-plot&quot; id=&quot;markdown-toc-first-bad-plot&quot;&gt;First, bad plot&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#normalisedbut-still-bad-plot&quot; id=&quot;markdown-toc-normalisedbut-still-bad-plot&quot;&gt;Normalised(but still bad) plot&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#clustering-time-series&quot; id=&quot;markdown-toc-clustering-time-series&quot;&gt;Clustering time-series&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#clustered-plot&quot; id=&quot;markdown-toc-clustered-plot&quot;&gt;Clustered plot&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/section&gt;
&lt;!-- /#table-of-contents --&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This most definitely won’t be a revelation for anyone working with time-series on a daily basis, but I came across the importance of proper techniques for visualising them quite recently in a work-related problem, so I decided to generalise the approach slightly and use publicly available data to demonstrate the importance of following method.&lt;/p&gt;

&lt;p&gt;We will focus on the visualisation suitable for identifying global trends and patterns in timeseries of FTSE 100 stocks. Other applications might require different forms of visualisation.&lt;/p&gt;

&lt;p&gt;It’s also worth mentioning that I am by no means an expert on the matter of stocks and financial markets(in fact everything I know was learnt in preparation for this post…), so any of my speculations should be taken with a bucketful of salt or ignored altogether. But if you have the urge to correct me, pleaso do so and I will alter the post.&lt;/p&gt;

&lt;p&gt;We will start from the very beginning - mining stocks names from LSE website - and documenting each step as we go, with a few unexpected(but planned) twists and cheeky cliffhangers.&lt;/p&gt;

&lt;h2 id=&quot;getting-ftse-100-stocks&quot;&gt;Getting FTSE 100 stocks&lt;/h2&gt;
&lt;p&gt;Our main data will come from Quandl, which stores all LSE stocks in datasets that have names like “LSE/HIK” where “HIK” is the stock’s name. FTSE 100 aggregated top 100 performing stocks on LSE, so we can use it as a reference for the most interesting stocks. Let’s mine the stock names from LSE’s website.&lt;/p&gt;

&lt;p&gt;Stock information is stored in HTML tables scattered across several pages with the same base url: “http://www.londonstockexchange.com/exchange/prices-and-markets/stocks/indices/summary/summary-indices-constituents.html?index=UKX&amp;amp;page=1”. Varying the “page” parameter from 1 to 6 we can get all 100 stocks. The script is therefore extremely straightforward:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;mine.py&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;requests&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;re&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;http://www.londonstockexchange.com/exchange/prices-and-markets/stocks/indices/summary/summary-indices-constituents.html?index=UKX&amp;amp;page={0}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;stocks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;stock_names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;page&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;_stocks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&amp;lt;td scope=&amp;quot;row&amp;quot; class=&amp;quot;name&amp;quot;&amp;gt;(.+?)&amp;lt;/td&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;page&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;_stock_names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&amp;lt;a.*title=&amp;quot;View detailed prices page&amp;quot; target=&amp;quot;&amp;quot;&amp;gt;(.+?)&amp;lt;/a&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;page&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;stocks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_stocks&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;stock_names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_stock_names&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;stock_codes.csv&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;w&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Stock, Name&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stocks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stock_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&amp;quot;, &amp;quot;&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;After it finishes, we get a little CSV file that looks something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Stock, Name
&quot;III&quot;, &quot;3I GRP.&quot;
&quot;ABF&quot;, &quot;A.B.FOOD&quot;
&quot;ADN&quot;, &quot;ABDN.ASSET.MAN.&quot;
&quot;ADM&quot;, &quot;ADMIRAL GRP&quot;
&quot;AGK&quot;, &quot;AGGREKO&quot;
&quot;AAL&quot;, &quot;ANGLO AMERICAN&quot;
&quot;ANTO&quot;, &quot;ANTOFAGASTA&quot;
&quot;ARM&quot;, &quot;ARM HLDGS.&quot;
&quot;AHT&quot;, &quot;ASHTEAD GRP.&quot;
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Names are not as important, but will come handy during visualisation time.&lt;/p&gt;

&lt;h2 id=&quot;getting-quandl-data-for-stocks&quot;&gt;Getting Quandl data for stocks&lt;/h2&gt;
&lt;p&gt;Having all the stocks names, we can now obtain the time-series describing how the stock price changed over time.&lt;/p&gt;

&lt;p&gt;We will need to install the Quandl library for R(see &lt;a href=&quot;https://www.quandl.com/help/r&quot;&gt;installation instructions&lt;/a&gt;, also worth setting up auth code to bypass 50-per-hour rate limits) and establish a portal to the &lt;a href=&quot;http://adolfoalvarez.cl/the-hitchhikers-guide-to-the-hadleyverse/&quot;&gt;Hadleyverse&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# assuming you installed it&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Quandl&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dplyr&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# general data wrangling, tbl_df, %&amp;gt;% operator&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stringr&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# query tokenization&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;lubridate&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# could be omitted, really, but I do love it too much&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;ggplot&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# beautiful plots&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now comes the more interesting part. As I said earlier, Quandl stores all the stocks data for LSE under codes like “LSE/AGK” - so running &lt;code&gt;Quandl(&quot;LSE/AGK&quot;)&lt;/code&gt; will immediately give you a data frame with stock data for Aggreko. There’s two caveats though - one, FTSE 100 changes more often than Quandl’s LSE database, so some stocks might be missing. Two, some stocks from FTSE 100 have periods(“.”, e.g. “BP.”” is stock name for British Petroleum) in them, but Quandl doesn’t allow periods in datasets names.&lt;/p&gt;

&lt;p&gt;To tackle problem number one we’ll wrap stock data extraction in a function that can handle retrieval errors gracefully. Second problem is not really a problem - we’ll just use &lt;code&gt;str_replace_all&lt;/code&gt; to replace periods with underscores(“_”).&lt;/p&gt;

&lt;p&gt;We will stack all the datasets for different stocks on top of each other to aid &lt;code&gt;ggplot&lt;/code&gt; in plotting this data later on. Here’s the function that extracts stocks data for a vector of stocks names:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;quandle_stocks &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stocks&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  
  f &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;kp&quot;&gt;tryCatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
      &lt;span class=&quot;kp&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;paste&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;LSE&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; x&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; sep &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;/&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
      &lt;span class=&quot;kp&quot;&gt;cbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Quandl&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;paste&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;LSE&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; x&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; sep &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;/&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; authcode &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; API_CODE&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; Stock &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; x&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 2&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    error &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;e&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;kp&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;e&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;NULL&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 3&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
  
  &lt;span class=&quot;kp&quot;&gt;do.call&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;rbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;lapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stocks&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;f&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 1&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;We apply &lt;code&gt;f&lt;/code&gt; over a vector of stocks names, and then use &lt;code&gt;do.call&lt;/code&gt; to call &lt;code&gt;rbind&lt;/code&gt; with all the extracted data frames as positional arguments - this gives us a long data frame with all the stocks stacked on top of each other.&lt;/li&gt;
  &lt;li&gt;Here we simply add stock’s name as a column to a dataset returned by &lt;code&gt;Quandl&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Any error with any particular stock will result in function returning &lt;code&gt;NULL&lt;/code&gt;, which will then be handled gracefully by &lt;code&gt;rbind&lt;/code&gt; - no data will simply be added to the resulting long data frame.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Having this function, one can call it like this: &lt;code&gt;quandle_stocks(c(&quot;BP_&quot;, &quot;AGK&quot;))&lt;/code&gt;. But we have already extracted all the stocks names we need, so let’s just use them keeping in mind the “.” vs. “_” issue.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;stock_codes &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; read.csv&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;stock_codes.csv&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; header&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; stringsAsFactors &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
all_stocks &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; stock_codes&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;Stock &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
                str_replace_all&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;\\.&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;_&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# replace &amp;quot;.&amp;quot; with &amp;quot;_&amp;quot;&lt;/span&gt;
                quandle_stocks &lt;span class=&quot;c1&quot;&gt;# pipe that vector in the function we defined earlier&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Which, after outputting some debug information(e.g. errors in retrieving stocks “DC_”, “SKY” and “TUI” at the time of writing) will produce a dataset with following structure:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;gt; glimpse(all_stocks)&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Observations: 29217
Variables:
$ Date       (date) 2015-06-05, 2015-06-04, 2015-06-03, 2015-06-02, 2015-06-01, 2015-05-29, 2015-05-28, 2015-05-27, 2015-05-2...
$ Price      (dbl) 550.5, 554.0, 564.0, 568.5, 560.0, 559.5, 559.5, 562.5, 553.5, 551.5, 560.0, 558.0, 553.5, 548.0, 537.5, 5...
$ High       (dbl) 555.62, 563.00, 570.00, 571.00, 565.10, 567.14, 571.50, 562.50, 556.00, 559.00, 561.00, 561.50, 555.00, 55...
$ Low        (dbl) 548.50, 553.50, 561.50, 560.00, 554.20, 558.50, 559.00, 553.50, 547.50, 548.50, 554.50, 553.50, 546.90, 53...
$ Volume     (dbl) 1149139, 798015, 1850002, 2512969, 1756197, 1198987, 1763846, 875144, 1252053, 1318332, 710568, 1047121, 1...
$ Last Close (dbl) 554.5, 563.5, 569.5, 561.5, 560.5, 563.0, 564.5, 554.5, 550.0, 559.5, 560.0, 555.5, 548.0, 539.0, 534.5, 5...
$ Change     (dbl) 4.0, 9.5, 5.5, 7.0, 0.5, 3.5, 5.0, 8.0, 3.5, 8.0, 0.0, 2.5, 5.5, 9.0, 3.0, 6.5, 16.5, 5.0, 8.5, 12.0, 12.2...
$ Var%       (dbl) 0.72, 1.69, 0.97, 1.25, 0.09, 0.62, 0.89, 1.44, 0.64, 1.43, 0.00, 0.45, 1.00, 1.67, 0.56, 1.23, 3.22, 0.99...
$ Stock      (fctr) III, III, III, III, III, III, III, III, III, III, III, III, III, III, III, III, III, III, III, III, III, ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The columns we’re most interested in are &lt;code&gt;Date&lt;/code&gt;, &lt;code&gt;Price&lt;/code&gt; and &lt;code&gt;Stock&lt;/code&gt;. Now, let’s get a feel of the date with increasingly better plots.&lt;/p&gt;

&lt;h2 id=&quot;first-bad-plot&quot;&gt;First, bad plot&lt;/h2&gt;
&lt;p&gt;First and most obvious way of plotting the stock data would be to treat it as timeseries - how the &lt;code&gt;Price&lt;/code&gt; changes depending on the &lt;code&gt;Date&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;all_stocks &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; ggplot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Date&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;Price&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; colour &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Stock&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
                    geom_line&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
                    guides&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;colour &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; guide_legend&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;ncol &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
                    theme&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;text &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; element_text&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;size&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
                    scale_x_date&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;expand&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
                    ggtitle&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;FTSE 100 stocks&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz-stock-data/ugly_plot.png&quot; alt=&quot;Ugly plot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It is obvious that this plot gives us a lot less information than the data actually contains - mainly due to horrifying amount of overlapping in the bottom part of the &lt;code&gt;Price&lt;/code&gt; scale. It’s also less than obvious to understand what line belongs to which stock - the colour brewer scale of ggplot2 is only good when you have less than 5 groups.&lt;/p&gt;

&lt;p&gt;One other thing will also become obvious on the subsequent plots - dramatic difference in stocks prices actually hides interesting trends.&lt;/p&gt;

&lt;h2 id=&quot;normalisedbut-still-bad-plot&quot;&gt;Normalised(but still bad) plot&lt;/h2&gt;
&lt;p&gt;Now, FTSE 100 aggregates stocks with varying performance - stocks trading at ~77£(&lt;strong&gt;LLOY&lt;/strong&gt;) are there together with those trading at ~6800£(&lt;strong&gt;NXT&lt;/strong&gt;). My first suspicion after looking at the first version of our plot was that trends in smaller stocks will be compressed until indistinguishable from a straight line by larger stocks displayed on the same scale.&lt;/p&gt;

&lt;p&gt;For example, let’s take those two stocks, LLOY and NXT, and display them on the same plot(just like the one we used before).&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;all_stocks &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; filter&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Stock &lt;span class=&quot;o&quot;&gt;%in%&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;NXT&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;LLOY&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
    ggplot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Date&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; Price&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; colour&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Stock&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        geom_line&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        theme&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;text &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; element_text&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;size&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        scale_x_date&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;expand&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        ggtitle&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;FTSE 100 smallest stock vs. biggest stock&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz-stock-data/lloy_vs_nxt.png&quot; alt=&quot;LLOY vs. NXT&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This example clearly shows the importance of scaling before plotting. In the end, for our analysis the absolute value matters less than the behaviour of the stock - how it changed relative to its minimum/maximum/average value(choose the appropriate descriptive statistic based on your application).&lt;/p&gt;

&lt;p&gt;So it makes sense to normalise the stocks prices to identify the trends. Let’s do exactly that.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;normalise &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stocks&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
   stocks &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; group_by&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Stock&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        mutate&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Price &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Price&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Price&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Price&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Price&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; ungroup
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This function normalises each stock by representing it as a fraction of the price range - this new, normalised Price will be zero when the stock reaches its absolute minimum, and will be one when it reaches its absolute maximum. Let’s try and plot those new lines all on the same plot:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;normalise&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;all_stocks&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
    ggplot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Date&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;Price&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; colour &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Stock&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        geom_line&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        guides&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;colour &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; guide_legend&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;ncol &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        theme&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;text &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; element_text&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;size&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        scale_x_date&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;expand&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        ggtitle&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;FTSE 100 stocks(normalised)&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz-stock-data/ugly_normalised_plot.png&quot; alt=&quot;Bad normalised plot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On the first sight it looks as if the plot only got worse. It’s certainly less pretty, but let’s take a look at what happened to the lines corresponding to LLOY and NXT:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;normalise&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;all_stocks&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; filter&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Stock &lt;span class=&quot;o&quot;&gt;%in%&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;NXT&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;LLOY&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
    ggplot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Date&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; Price&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; colour&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Stock&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        geom_line&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        theme&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;text &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; element_text&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;size&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        scale_x_date&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;expand&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        ggtitle&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;FTSE 100 smallest stock vs. biggest stock(normalised&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz-stock-data/lloy_vs_nxt_normalised.png&quot; alt=&quot;LLOY vs. NXT normalised&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Much better, isn’t it? For the purposes of trend analysis - this representation is much more preferrable. If you were to invest in FTSE 100 stocks, you’d invest proportionally to the sizes of the stocks and then only care about the dynamics of your relative investments - not the absolute value for each stock.&lt;/p&gt;

&lt;p&gt;This representation lets us identify periods of steady growth and compare speeds of growth between stocks of any value. The absolute value of the stock comes later on when the investment portfolio is being formed.&lt;/p&gt;

&lt;p&gt;Also, this plot identifies some significant problems with the data. A careful observer will notice straight lines running across the plot - these are signs of missing data points. We will address this problem later.&lt;/p&gt;

&lt;h2 id=&quot;clustering-time-series&quot;&gt;Clustering time-series&lt;/h2&gt;
&lt;p&gt;Now, we can make a bold assumption that certain stocks behave similarly to other stocks - for example there must be a significant amount of steady risers - stocks that have been growing linearly and consistently until the last data point recorded. Also we’d expect to see several stocks that took a big hit from which they are recovering with varying success.&lt;/p&gt;

&lt;p&gt;All those assumptions can be expressed graphically - how certain lines on our big messy plot are similar to other lines. It only makes sense to group them together and separate the plot into several smaller ones that only concentrate on similar stocks.&lt;/p&gt;

&lt;p&gt;We’ll define clusters of stock behaviour. First thing one needs to address is that clustering algorithms impose a strict rule on the number of dimensions for each data point - it must be the same across all data points. It’s not the case in our data, as the histogram below will show, some stocks have more recorded data points, some - less.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;all_stocks &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
    count&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Stock&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
    ggplot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        geom_histogram&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;binwidth&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        xlab&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Number of data points&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        ylab&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Number of stocks&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
        theme&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;text &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; element_text&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;size&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz-stock-data/data_per_stock.png&quot; alt=&quot;Data points per stock&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Even though the majority of stocks has more than 300 data points(in fact 75% of stocks have more than 305), the numbers still vary, plus there’s plenty of stocks with significantly fewer data.&lt;/p&gt;

&lt;p&gt;For any form of clustering to be applied we need to convert all those data points into a fixed number of dimensions, say, 100. To do that, we’ll use approximated function of stocks behaviour and its values at 100 points taken over a regular grid. First, let’s become acquainted with the &lt;code&gt;approxfun&lt;/code&gt; function from base R. Take a look at the example:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;points &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
values &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

new_points &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.94&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
approximated_function &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; approxfun&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;points&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; values&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

new_values &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; approximated_function&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;new_points&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;code&gt;approxfun&lt;/code&gt; simply approximates the function given points and function’s values at those points and then returns a new function which can then be directly used to get values at a new set of points. For our purposes I think it’s good enough. Note, that we could’ve re-written the entire example as &lt;code&gt;approxfun(c(0,0.5,1), c(0.8, 0.3, 0.9))(c(0.1,0.2,0.9,0.94))&lt;/code&gt; and it would give the same result as &lt;code&gt;new_values&lt;/code&gt;. That’s the notation we’ll use for brevity later.&lt;/p&gt;

&lt;p&gt;Now, given that we are about to compress the date axis of each stock to the same scale, it’s no longer appropriate to use actual dates, we’ll use numbers from 0.0 to 1.0 instead, where 0.0 is the first data point for stock, and 1.0 is the last one. We will then use &lt;code&gt;approxfun&lt;/code&gt; and a fixed grid of points to get a decent approximation of what each stock’s behaviour looks like as a 100-dimensional vector.&lt;/p&gt;

&lt;p&gt;So let’s write a function that compresses our stock data points into a fixed dimensionality vector.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;smooth &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stock&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; ndim&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
  normalise&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stock&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; group_by&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Stock&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 1&lt;/span&gt;
    arrange&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Date&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
    mutate&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;NormDate &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;as.numeric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Date&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;as.numeric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Date&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;as.numeric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Date&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;as.numeric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Date&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#2&lt;/span&gt;
    do&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;data_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Stock&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;Stock&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
                  Point&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; length.out&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;ndim&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#3&lt;/span&gt;
                  Price&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;approxfun&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;NormDate&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;Price&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; length.out&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;ndim&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#4&lt;/span&gt;
    ungroup
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;We use the &lt;code&gt;normalise&lt;/code&gt; function we defined earlier to scale prices.&lt;/li&gt;
  &lt;li&gt;We convert each actual Date object to number from 0.0 to 1.0&lt;/li&gt;
  &lt;li&gt;A grid of &lt;code&gt;ndim&lt;/code&gt;(100) points over [0.0, 1.0]&lt;/li&gt;
  &lt;li&gt;See example above, we basically approximate the Price as a function of normalised date and then evaluate this function on a regular grid of 100 points.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now, let’s take a look at LLOY and NXT stocks in this representation to make sure that our smoothing actually worked as expected:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz-stock-data/lloy_vs_nxt_smoothed.png&quot; alt=&quot;LLOY vs. NXT smoothed&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Looks good to me! Sure, we lost some detail by performing an under-sampling(100 points instead of ~325 in original data), but we managed to capture the main trends. And now we can use this data directly in any clustering algorithm.&lt;/p&gt;

&lt;p&gt;Well, almost directly. Most clustering algorithms available in R will expect data in the shape of a matrix, where columns represent variables and rows represent observations. Our data is… well, somewhat different. Here’s what it looks like right now:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;gt; smooth(all_stocks)&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Source: local data frame [9,800 x 3]

   Stock      Point     Price
1    III 0.00000000 0.1692308
2    III 0.01010101 0.2132190
3    III 0.02020202 0.2398376
4    III 0.03030303 0.2243627
5    III 0.04040404 0.2448004
6    III 0.05050505 0.2379277
7    III 0.06060606 0.1789759
8    III 0.07070707 0.2052786
9    III 0.08080808 0.1417550
10   III 0.09090909 0.1376494
..   ...        ...       ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What we want is for each Stock to spread the 100 values of Price into 100 different columns. Let’s use &lt;code&gt;tidyr&lt;/code&gt;’s conveniently named &lt;code&gt;spread&lt;/code&gt; function:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;smooth&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stock&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; group_by&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Stock&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
    arrange&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Point&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 1&lt;/span&gt;
    mutate&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;P&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;paste&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;P&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; str_pad&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dense_rank&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Point&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; pad&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;0&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 2&lt;/span&gt;
    select&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;Stock&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;Point&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 3&lt;/span&gt;
    spread&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;P&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; Price&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 4&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;I always sort the points in groups because I’m severely paranoid and I think I once was bitten by this. May be it was a dream. Better safe than sorry.&lt;/li&gt;
  &lt;li&gt;I added a fake column whose values will become new column names&lt;/li&gt;
  &lt;li&gt;We help &lt;code&gt;spread&lt;/code&gt; by only leaving the new variable names and their values&lt;/li&gt;
  &lt;li&gt;This “zips” fake column names with their respective values and then performs the transformation.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Our data will now look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Source: local data frame [19 x 101]

   Stock     P 0001     P 0002     P 0003     P 0004     P 0005     P 0006     P 0007     P 0008     P 0009      P 0010     P 0011
1    HIK 0.00000000 0.04778993 0.10322777 0.12273866 0.14169262 0.18948128 0.16580846 0.24235589 0.30799727 0.284597858 0.31711855
2   HSBA 0.75647172 0.92336355 0.80954318 0.70199599 0.65978093 0.55019030 0.37168424 0.31514570 0.44932547 0.488567361 0.49434905
3    IMT 0.04666057 0.09154676 0.07972682 0.12534309 0.15955530 0.16854732 0.10621309 0.12498267 0.11539919 0.119021875 0.11380964
4    IHG 0.10749507 0.11423406 0.05818540 0.07270934 0.07175303 0.04342239 0.02097902 0.02719503 0.05718925 0.064042795 0.07073696
5   ITRK 0.80126183 0.85571806 0.92242084 0.83471943 0.94544817 0.94587303 0.82372622 0.83618520 0.87725839 0.964757990 0.91272345
6    IAG 0.41821809 0.44404064 0.43303044 0.42396035 0.41451080 0.39526247 0.35026797 0.38693786 0.31710724 0.337080916 0.39977232
7   INTU 0.36016949 0.35433787 0.36468855 0.26836158 0.26954931 0.08926126 0.10156651 0.11296225 0.08378274 0.044087057 0.09383025
8    ITV 0.37619048 0.38984127 0.32832131 0.29688312 0.30279942 0.26889851 0.23904762 0.31189033 0.22582973 0.193766234 0.24810967
9   JMAT 0.66908213 0.67400454 0.65822476 0.64273166 0.63087396 0.55390865 0.39013322 0.48477529 0.45874201 0.617698726 0.66666667
10   KGF 0.58982412 0.67195828 0.68981904 0.66554363 0.73966423 0.73772270 0.73540049 0.78666058 0.76612228 0.840452261 0.95793361
11  LAND 0.20612813 0.11443122 0.11493768 0.08213050 0.09186573 0.05783930 0.07942939 0.02827720 0.06225674 0.123676880 0.15188093
12  LGEN 0.34033149 0.38640549 0.40861655 0.38844802 0.37599196 0.33516379 0.25578436 0.08474803 0.03182097 0.002611753 0.07527206
13  LLOY 0.57475083 0.63578895 0.57077419 0.61985302 0.54778684 0.58262022 0.41383939 0.45179368 0.41418057 0.191902413 0.31068157
14   LSE 0.19591346 0.28328052 0.31778118 0.30364948 0.30124563 0.28670115 0.16881556 0.29108392 0.24732906 0.257320804 0.27684295
15   MKS 0.47507056 0.52756991 0.56277260 0.56042076 0.56305767 0.46727387 0.36477665 0.41573306 0.33162291 0.326121041 0.40839249
16  MGGT 0.59240821 0.54345100 0.51462352 0.46993268 0.44094963 0.26641650 0.14006902 0.27135072 0.24925044 0.312930173 0.32273576
17  MERL 0.25826772 0.30858984 0.36876906 0.35025054 0.25425117 0.33176648 0.45058459 0.37253374 0.37851746 0.365282749 0.38504732
18  MNDI 0.06233766 0.15798242 0.18095238 0.21605667 0.25892693 0.25929424 0.21978224 0.22172373 0.17453321 0.151305260 0.20829070
19   MRW 0.91309131 0.87508751 0.95967375 0.91279128 0.90619062 0.89724528 0.60376038 0.62776278 0.64938716 0.675434210 0.59409274
Variables not shown: P 0012 (dbl), P 0013 (dbl), P 0014 (dbl), P 0015 (dbl), P 0016 (dbl), P 0017 (dbl), P 0018 (dbl), P 0019 (dbl),
  P 0020 (dbl), P 0021 (dbl), P 0022 (dbl), P 0023 (dbl), P 0024 (dbl), P 0025 (dbl), P 0026 (dbl), P 0027 (dbl), P 0028 (dbl), P
  0029 (dbl), P 0030 (dbl), P 0031 (dbl), P 0032 (dbl), P 0033 (dbl), P 0034 (dbl), P 0035 (dbl), P 0036 (dbl), P 0037 (dbl), P 0038
  (dbl), P 0039 (dbl), P 0040 (dbl), P 0041 (dbl), P 0042 (dbl), P 0043 (dbl), P 0044 (dbl), P 0045 (dbl), P 0046 (dbl), P 0047
  (dbl), P 0048 (dbl), P 0049 (dbl), P 0050 (dbl), P 0051 (dbl), P 0052 (dbl), P 0053 (dbl), P 0054 (dbl), P 0055 (dbl), P 0056
  (dbl), P 0057 (dbl), P 0058 (dbl), P 0059 (dbl), P 0060 (dbl), P 0061 (dbl), P 0062 (dbl), P 0063 (dbl), P 0064 (dbl), P 0065
  (dbl), P 0066 (dbl), P 0067 (dbl), P 0068 (dbl), P 0069 (dbl), P 0070 (dbl), P 0071 (dbl), P 0072 (dbl), P 0073 (dbl), P 0074
  (dbl), P 0075 (dbl), P 0076 (dbl), P 0077 (dbl), P 0078 (dbl), P 0079 (dbl), P 0080 (dbl), P 0081 (dbl), P 0082 (dbl), P 0083
  (dbl), P 0084 (dbl), P 0085 (dbl), P 0086 (dbl), P 0087 (dbl), P 0088 (dbl), P 0089 (dbl), P 0090 (dbl), P 0091 (dbl), P 0092
  (dbl), P 0093 (dbl), P 0094 (dbl), P 0095 (dbl), P 0096 (dbl), P 0097 (dbl), P 0098 (dbl), P 0099 (dbl), P 0100 (dbl)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now this data can be used in a clustering algorithm, if we convert it to a proper matrix first. Let’s arrange the previous spreading step and the clsutering into one nice function:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;cluster_stocks &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stock&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; N&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
  smooth&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stock&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; group_by&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Stock&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
    arrange&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Point&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
    mutate&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;P&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;paste&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;P&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; str_pad&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dense_rank&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Point&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; pad&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;0&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
    select&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;Stock&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;Point&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
    spread&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;P&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; Price&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
    ungroup &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
    do&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;data_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Stock&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;Stock&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                  Cluster &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; kmeans&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;as.matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;select&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;Stock&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; N&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;cluster&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Notes:
 1. Here we just run basic &lt;code&gt;kmeans&lt;/code&gt; algorithm on the matrix with all data points for stocks and a given number of clusters. We remove the column “Stock” and use &lt;code&gt;as.matrix&lt;/code&gt; to simplify our object. Then we take the cluster numbers and return them in a new column.&lt;/p&gt;

&lt;p&gt;Here’s the sample result:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;gt; cluster_stocks(all_stocks, N=10)&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Source: local data frame [98 x 2]

   Stock Cluster
1    III       6
2    ABF       3
3    ADN       4
4    ADM       4
5    AGK       1
6    AAL       8
7   ANTO       7
8    ARM       2
9    AHT      10
10   AZN       3
..   ...     ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;clustered-plot&quot;&gt;Clustered plot&lt;/h2&gt;
&lt;p&gt;Now we can use clustering information to group similar stocks together. Let’s just create facets for each cluster and plot only stocks belonging to that cluster. For each cluster we will also display a line that best represents the pattern shared by the stocks in it - we’ll use &lt;code&gt;geom_smooth&lt;/code&gt; for that.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;normalise&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;all_stocks&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
  inner_join&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;cluster_stocks&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;all_stocks&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; N&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
  ggplot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Date&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; Price&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; colour &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Stock&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
    geom_line&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;alpha&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
    geom_smooth&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;group&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Cluster&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; size&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; alpha&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
    guides&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;colour &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; guide_legend&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;ncol &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
    theme&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;text &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; element_text&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;size&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; strip.text&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;element_text&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;size&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
    scale_x_date&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;expand&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
    ggtitle&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;FTSE 100 stocks(normalised and clustered)&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
    facet_wrap&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;Cluster&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And here it is, the final plot:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz-stock-data/clustered-plot.png&quot; alt=&quot;FTSE 100 stocks, normalised and clustered&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Even this simple plot shows us some interesting differences between stocks and how they recover from drops - stocks in cluster number 2 are less desirable than stocks in cluster number 9, as the latter ones seem to recover steadily form the hit. Is cluster number 2 just a stretched out version of first 50% of data points of cluster number 1?&lt;/p&gt;

&lt;p&gt;Many interesting insights can be drawn just from looking at stocks in this grouped manner. Interesting clusters can then be examined more thoroughly on an absolute price plot.&lt;/p&gt;

&lt;p&gt;Many other clustering techniques can be used, and I would especially recommend interactive hierarchical clustering to define a good number of cluster.&lt;/p&gt;

&lt;p&gt;Code can be found in the &lt;a href=&quot;https://github.com/keynmol/keynmol.github.io/tree/master/code/viz-stock-data&quot;&gt;accompanying Github repo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Thanks for getting this far!&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/dataviz/visualising-real-world-timeseries/&quot;&gt;Visualising timeseries: stocks data and global trends&lt;/a&gt; was originally published by Anton Sviridov at &lt;a href=&quot;&quot;&gt;The many shades of data&lt;/a&gt; on June 10, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Data Analysis vs. Google search history]]></title>
  <link rel="alternate" type="text/html" href="/data%20analysis/data-analysis-vs-google-search-history/" />
  <id>/data%20analysis/data-analysis-vs-google-search-history</id>
  <published>2015-05-31T00:00:00+01:00</published>
  <updated>2015-05-31T00:00:00+01:00</updated>
  <author>
    <name>Anton Sviridov</name>
    <uri></uri>
    <email>keynmol@gmail.com</email>
  </author>
  <content type="html">
    &lt;section id=&quot;table-of-contents&quot; class=&quot;toc&quot;&gt;
  &lt;header&gt;
    &lt;h3&gt;&lt;i class=&quot;fa fa-book&quot;&gt;&lt;/i&gt; Overview&lt;/h3&gt;
  &lt;/header&gt;
&lt;div id=&quot;drawer&quot;&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot; id=&quot;markdown-toc-introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#getting-data&quot; id=&quot;markdown-toc-getting-data&quot;&gt;Getting data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#preparing-data&quot; id=&quot;markdown-toc-preparing-data&quot;&gt;Preparing data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#languages-stats&quot; id=&quot;markdown-toc-languages-stats&quot;&gt;Languages stats&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#tokenizing-queries&quot; id=&quot;markdown-toc-tokenizing-queries&quot;&gt;Tokenizing queries&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#words-ranking-and-zipfs-law&quot; id=&quot;markdown-toc-words-ranking-and-zipfs-law&quot;&gt;Words ranking and Zipf’s law&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#trends-and-topics&quot; id=&quot;markdown-toc-trends-and-topics&quot;&gt;Trends and topics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/section&gt;
&lt;!-- /#table-of-contents --&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;A man is defined not by the way he looks, but what he looks for. And these days it is exceptionally easy to find out, what you’re looking for – Google provides access to your search history starting from a certain point in time which is probably different for everyone(my archive started from 2011 though it goes without saying that I’ve been using Google long before that). And while in different periods of my life I have found myself googling some &lt;strong&gt;really weird shit&lt;/strong&gt;(like, really weird, from the depths of underwebs), I decided to rely on the safety of large numbers and post the results of this trip down the memory lane no matter what kind of deviation they shall display.&lt;/p&gt;

&lt;p&gt;This doesn’t serve any scientific purpose, it’s more of a demonstration of the use of fantastic packages R can offer, applied to a dataset from a real world. This is not a tutorial on R language or aforementioned packages per se, but rather a primer of their usage in real(well, almost) world.&lt;/p&gt;

&lt;p&gt;It’s a well-known fact, that 70%-90% of data scientist’s time is spent shaping the data into shape needed for exploratory analysis. And whilst there’s no upper-boundary on the dirtiness of data(some things I’ve seen still keep me awake at night, especially in publicly available governmental datasets), this data will be somewhere in the bottom 10% percentile – most of the time is spent massaging the data, which is more fun than cleaning it and battling with missing values.&lt;/p&gt;

&lt;h2 id=&quot;getting-data&quot;&gt;Getting data&lt;/h2&gt;

&lt;p&gt;My previous attempt to analyse my own google searches was stumped by Google’s own malfunction during archive creation, but this time I went to &lt;a href=&quot;https://history.google.com/history/&quot;&gt;Web &amp;amp; App Activity&lt;/a&gt; and succesfully managed to download the archive. The main thing it contains is json files with queries:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;2011-01-01 January &lt;span class=&quot;m&quot;&gt;2011&lt;/span&gt; to March 2011.json    2012-07-01 July &lt;span class=&quot;m&quot;&gt;2012&lt;/span&gt; to September 2012.json   2014-01-01 January &lt;span class=&quot;m&quot;&gt;2014&lt;/span&gt; to March 2014.json
2011-04-01 April &lt;span class=&quot;m&quot;&gt;2011&lt;/span&gt; to June 2011.json       2012-10-01 October &lt;span class=&quot;m&quot;&gt;2012&lt;/span&gt; to December 2012.json 2014-04-01 April &lt;span class=&quot;m&quot;&gt;2014&lt;/span&gt; to June 2014.json
2011-07-01 July &lt;span class=&quot;m&quot;&gt;2011&lt;/span&gt; to September 2011.json   2013-01-01 January &lt;span class=&quot;m&quot;&gt;2013&lt;/span&gt; to March 2013.json    2014-07-01 July &lt;span class=&quot;m&quot;&gt;2014&lt;/span&gt; to September 2014.json
2011-10-01 October &lt;span class=&quot;m&quot;&gt;2011&lt;/span&gt; to December 2011.json 2013-04-01 April &lt;span class=&quot;m&quot;&gt;2013&lt;/span&gt; to June 2013.json       2014-10-01 October &lt;span class=&quot;m&quot;&gt;2014&lt;/span&gt; to December 2014.json
2012-01-01 January &lt;span class=&quot;m&quot;&gt;2012&lt;/span&gt; to March 2012.json    2013-07-01 July &lt;span class=&quot;m&quot;&gt;2013&lt;/span&gt; to September 2013.json   2015-01-01 January &lt;span class=&quot;m&quot;&gt;2015&lt;/span&gt; to March 2015.json
2012-04-01 April &lt;span class=&quot;m&quot;&gt;2012&lt;/span&gt; to June 2012.json       2013-10-01 October &lt;span class=&quot;m&quot;&gt;2013&lt;/span&gt; to December 2013.json 2015-04-01 April &lt;span class=&quot;m&quot;&gt;2015&lt;/span&gt; to June 2015.json&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Each JSON has the same structure:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;quot;event&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;query&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;quot;id&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
               &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;quot;timestamp_usec&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;1325324851354700&amp;quot;&lt;/span&gt;
               &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;quot;query_text&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;jonathan ross dexter&amp;quot;&lt;/span&gt;
         &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;query&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;quot;query_text&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;johnatan ross dexter&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;quot;id&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
               &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;quot;timestamp_usec&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;1325324848005857&amp;quot;&lt;/span&gt;
               &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Timestamps are in microseconds, but we don’t need this kind of precision, so we can safely trim last 6 digits and get a regular UNIX timestamp that R can understand. Also, each query can be associated with several &lt;code&gt;id&lt;/code&gt;s, each having a different timestamp – to my understanding, this groups image searches. We’ll ignore that and just take the minimum of timestamps(or we could take the first one).&lt;/p&gt;

&lt;p&gt;Given that the idea of working with multiple(!) JSON(!!) files(!!!) and R gives me shivers(my knowledge of available packages is probably severely outdated), I wrote a tiny Python script that converts everything into a nice flat csv dataset:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sys&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;json&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;glob&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os.path&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;csv&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Usage: create_dataset.py searches_folder&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fold&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;writer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;csv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DictWriter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stdout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fieldnames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Timestamp&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;Query&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quoting&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;csv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;QUOTE_NONNUMERIC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;writer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writeheader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# scan all json files in the folder&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;queries_file&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;*.json&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# load json&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queries_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;queries&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;queries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;event&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;query&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# extract timestamp with removed microseconds&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;timestamp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;timestamp_usec&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query_id&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;writer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writerow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Timestamp&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;Query&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;query_text&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]})&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;After running this script on the folder with extracted JSON files, we will have a csv file with two columns: timestamp and query. Buckle up, we’re going on an adventuR(sorry). Fire up your R console, or RStudio(if you still don’t use it, you need to stop here for a moment and rethink your life priorities).&lt;/p&gt;

&lt;h2 id=&quot;preparing-data&quot;&gt;Preparing data&lt;/h2&gt;
&lt;p&gt;First, let’s establish a portal to &lt;a href=&quot;http://adolfoalvarez.cl/the-hitchhikers-guide-to-the-hadleyverse/&quot;&gt;Hadleyverse&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dplyr&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# general data wrangling, tbl_df, %&amp;gt;% operator&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stringr&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# query tokenization&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;lubridate&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# could be omitted, really, but I do love it too much&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;ggplot&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# beautiful plots&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If you don’t have any of those packages, install them, they are guaranteed to transform the way you see data analysis, both in R and in general. Let’s load our dataset and have a first look at it:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# immediately convert it do tbl_df for pretty printing&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; ds &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; tbl_df&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;read.csv&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;dataset.csv&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; stringsAsFactors &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# convert integer timestamp to R&amp;#39;s native datetime object(POSIXct)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; ds&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;TimeStamp &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;as.POSIXct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;ds&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;Timestamp&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; origin &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;1970-01-01&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# print some rows starting from the most recent queries&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; ds &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; arrange&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;desc&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;TimeStamp&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
Source&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; local &lt;span class=&quot;kt&quot;&gt;data frame&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;328&lt;/span&gt; x &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    Timestamp             Query           TimeStamp
&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;1433067125&lt;/span&gt;       colourout R &lt;span class=&quot;m&quot;&gt;2015-05-31&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;05&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;1433067122&lt;/span&gt;         colourout &lt;span class=&quot;m&quot;&gt;2015-05-31&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;02&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;1433023552&lt;/span&gt;    predestination &lt;span class=&quot;m&quot;&gt;2015-05-30&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;05&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;52&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;1433018900&lt;/span&gt;       sarah snook &lt;span class=&quot;m&quot;&gt;2015-05-30&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;48&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;1433018895&lt;/span&gt;    predestination &lt;span class=&quot;m&quot;&gt;2015-05-30&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;48&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;1433014242&lt;/span&gt; focaccia di recco &lt;span class=&quot;m&quot;&gt;2015-05-30&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;42&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;1433011327&lt;/span&gt;                 н &lt;span class=&quot;m&quot;&gt;2015-05-30&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;19&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;07&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;1433004348&lt;/span&gt;          Thatcher &lt;span class=&quot;m&quot;&gt;2015-05-30&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;48&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;1432997333&lt;/span&gt;    predestination &lt;span class=&quot;m&quot;&gt;2015-05-30&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;48&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;53&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1432993008&lt;/span&gt;  weather brighton &lt;span class=&quot;m&quot;&gt;2015-05-30&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;36&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;48&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I kept the original integer Timestamp to see if the conversion worked as I expected. Also, I had to reorder the data frame, but only because my oldest queries were almost exclusively in Russian, which would reduce the demonstraction power.&lt;/p&gt;

&lt;h2 id=&quot;languages-stats&quot;&gt;Languages stats&lt;/h2&gt;
&lt;p&gt;I decided to take a look at how the language of queries changed over time. I’ll use a very crude and inaccurate method of language detection(thankfully, Russian and English have completely different character sets), which will misfire on queries like “translate &lt;russian word=&quot;&quot;&gt;&quot;, of which I have a few. But too few to affect the general trend.&lt;/russian&gt;&lt;/p&gt;

&lt;p&gt;So let’s take a look at the code that generates the plot with &lt;a href=&quot;http://mathworld.wolfram.com/CumulativeSum.html&quot;&gt;cumulative sums&lt;/a&gt; of number of queries in each language per month. This will demonstrate the power and, even more importantly, the readability of the methods, provided by Hadleyverse’s packages:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; language_usage_plot &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; ds &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;c1&quot;&gt;# we group all queries by the month and calculate the counts below in that month&lt;/span&gt;
        group_by&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Month&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;round_date&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;TimeStamp&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;month&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# round each timestamp to the month it falls in&lt;/span&gt;
        summarise&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Russian&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;str_detect&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Query&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;[а-яА-я]&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# count Russian queries&lt;/span&gt;
                  English&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;str_detect&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Query&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;[a-zA-Z]&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# count English characters&lt;/span&gt;
        ungroup &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        gather&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Language&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; Queries&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;Month&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# see notes below&lt;/span&gt;
        group_by&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Language&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        arrange&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Month&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# order is important for cumsum to make sense&lt;/span&gt;
        mutate&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Number of queries&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;cumsum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Queries&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# will sum them across months in the Language group&lt;/span&gt;
        ungroup &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        ggplot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Month&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`Number of queries`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; colour&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Language&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
          geom_line&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;gather&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Language&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; Queries&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;Month&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This is a very important step, which converts data in wide format:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;Source: &lt;span class=&quot;nb&quot;&gt;local &lt;/span&gt;data frame &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;54&lt;/span&gt; x 3&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;

        Month Russian English
&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;  2011-01-01       &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;       4
&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;  2011-02-01       &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;      10
&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;  2011-03-01       &lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;       6
&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;  2011-04-01       &lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;      32
&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;  2011-05-01       &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;      10&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To data in long “molten” format:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;Source: &lt;span class=&quot;nb&quot;&gt;local &lt;/span&gt;data frame &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;108&lt;/span&gt; x 3&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;

        Month Language Queries
&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;  2011-01-01  Russian       2
&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;  2011-02-01  Russian       2
&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;  2011-03-01  Russian       9
&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;  2011-04-01  Russian       9
&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;  2011-05-01  Russian       8&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note the doubled number of rows and different organisation of columns. This format is native to ggplot, hence the extremely simple plotting command at the end of the pipeline.&lt;/p&gt;

&lt;p&gt;This code produces a plot like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/google-searches/language_stats.png&quot; alt=&quot;Query language stats&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Which shows, that my transition into English culture started long before actual moving to London.&lt;/p&gt;

&lt;h2 id=&quot;tokenizing-queries&quot;&gt;Tokenizing queries&lt;/h2&gt;

&lt;p&gt;With that out of the way, let’s do something slightly more entertaining – express my life in trends and topics without defining them manually. We will use word tokens as topics. So let’s break down each query into a list of words:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;words_index &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; ds &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
  group_by&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Query&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; TimeStamp&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# treat repeated queries as separate entities to have more consistent counts&lt;/span&gt;
  do&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;data_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Word &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;tolower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;str_extract_all&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;Query&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;([a-zA-Zа-яA-Я&amp;#39;]+)&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# see notes below&lt;/span&gt;
  ungroup&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The line&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;do&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;data_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Word &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;tolower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;str_extract_all&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;Query&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;([a-zA-Zа-яA-Я&amp;#39;]+)&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# see notes below&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;makes use of &lt;a href=&quot;https://github.com/hadley/dplyr#do&quot;&gt;dplyr’s do&lt;/a&gt; method that provides a convenient method for running an arbitrary computation on a group of rows. In our particular case we merely extract all sequences of cyrillic and latin characters(note the apostrophe to avoid extracting “s” from “it’s” and other similar cases). Then we &lt;a href=&quot;https://stat.ethz.ch/R-manual/R-devel/library/base/html/unlist.html&quot;&gt;unlist&lt;/a&gt; the nested structure to get a plain vector of words which will then be added to the modified group(with all words in lower case).&lt;/p&gt;

&lt;p&gt;It’s worth noting, that this operation takes a suprising amount of time(about a minute) for such a small dataset. Especially when extraction itself is rather fast:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;system.time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;X &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;tolower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;str_extract_all&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;ds&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;Query&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;([a-zA-Zа-яA-Я&amp;#39;]+)&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt;
   user  system elapsed 
  &lt;span class=&quot;m&quot;&gt;1.863&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0.046&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;1.935&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;My suspicion is that the constant reallocation of memory(we cannot predict the number of rows in the result unless we actually extract the words, that’s the catch) slows down the process. Or may be some internal unomptimized routines in dplyr. Either way, I don’t mind waiting for a minute, but I would certainly redesign this solution for a bigger dataset.&lt;/p&gt;

&lt;p&gt;The general rule is to create the most obvious and readable solution first, and then optimise it bit by bit, should it prove necessary.&lt;/p&gt;

&lt;h2 id=&quot;words-ranking-and-zipfs-law&quot;&gt;Words ranking and Zipf’s law&lt;/h2&gt;

&lt;p&gt;Back to words. Let’s look at the rankings:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; words_index &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; count&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Word&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; arrange&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;desc&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
Source&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; local &lt;span class=&quot;kt&quot;&gt;data frame&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;390&lt;/span&gt; x &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

     Word    n
&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;    ruby &lt;span class=&quot;m&quot;&gt;1055&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;     the  &lt;span class=&quot;m&quot;&gt;964&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;       r  &lt;span class=&quot;m&quot;&gt;849&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;      &lt;span class=&quot;kr&quot;&gt;in&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;783&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;  python  &lt;span class=&quot;m&quot;&gt;746&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;      to  &lt;span class=&quot;m&quot;&gt;706&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;  london  &lt;span class=&quot;m&quot;&gt;686&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;      of  &lt;span class=&quot;m&quot;&gt;643&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;  chords  &lt;span class=&quot;m&quot;&gt;559&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;      a  &lt;span class=&quot;m&quot;&gt;404&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;What “the”..? Not good. Let’s filter out the stopwords. Gladly, R handles URLs better than any language:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# download a list of stopwords&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; stopwords &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;
&lt;span class=&quot;kp&quot;&gt;suppressWarnings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;readLines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&amp;quot;http://xpo6.com/wp-content/uploads/2015/01/stop-word-list.txt&amp;quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# filter our index&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; words_index &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; words_index &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; filter&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Word &lt;span class=&quot;o&quot;&gt;%in%&lt;/span&gt; stopwords&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; words_index &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; count&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Word&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; arrange&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;desc&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
Source&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; local &lt;span class=&quot;kt&quot;&gt;data frame&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;157&lt;/span&gt; x &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

     Word    n
&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;    ruby &lt;span class=&quot;m&quot;&gt;1055&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;       r  &lt;span class=&quot;m&quot;&gt;849&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;  python  &lt;span class=&quot;m&quot;&gt;746&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;  london  &lt;span class=&quot;m&quot;&gt;686&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;  chords  &lt;span class=&quot;m&quot;&gt;559&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;  lyrics  &lt;span class=&quot;m&quot;&gt;346&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;  ubuntu  &lt;span class=&quot;m&quot;&gt;298&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;  ggplot  &lt;span class=&quot;m&quot;&gt;284&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;   rails  &lt;span class=&quot;m&quot;&gt;257&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt; oracle  &lt;span class=&quot;m&quot;&gt;232&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Much better now. One look at the numbers suggests the kind of distribution I used to see al the time during my relatively brief experience with Information Retrieval - Zipf law. Let’s take a closer look at it:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; word_rank_plot &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; words_index &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
    count&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Word&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# see code above&lt;/span&gt;
    top_n&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; n&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# take top 100 words&lt;/span&gt;
    ggplot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dense_rank&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;n&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; n&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# we use dense_rank(-n) to get rank(possibly repeated) for each word&lt;/span&gt;
      geom_line&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; xlab&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Word rank&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      ylab&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Number of queries&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      scale_x_continuous&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;breaks &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; by &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      geom_text&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        label &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Word&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        alpha &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; dense_rank&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;n&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; 
        hjust &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;-0.8&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# log to make colour fade slower&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; show_guide &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# don&amp;#39;t show legend for alpha&lt;/span&gt;
      geom_point&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
      ggtitle&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Word rank&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This is a relatively simple plot that doesn’t use too many of the ideas we haven’t used before. And this is what it looks like:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/google-searches/word-ranks.png&quot; alt=&quot;Words ranking and Zipf&#39;s law&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Just as suspected! This looks like a perfect example of &lt;a href=&quot;http://en.wikipedia.org/wiki/Zipf%27s_law&quot;&gt;Zipf’s law&lt;/a&gt;, the kind of plot you usually see in the books(or log-log plot, but it’s boring).&lt;/p&gt;

&lt;p&gt;The interesting thing about this finding is that even on such small dataset with short queries, the law, which is supposed to hold for English language, still shines through. Even though “the” is only in second place - but this can be easily explained by the fact that any person familiar with how search engines work will usually omit this and other stopwords from the query as they bear little or no significance on results(with exceptions, for example “the who” vs. “who”).&lt;/p&gt;

&lt;h2 id=&quot;trends-and-topics&quot;&gt;Trends and topics&lt;/h2&gt;

&lt;p&gt;Now, let’s do slightly more plotting - I have a sucpicion that the changes in my development stack were greatly affected by two events – moving to London to study and getting a job there a year later. I will demonstrate that change in the best way possible(subjective, of course), and then explain why those changes happened. But you can safely skip the explanation if you’re not interested in my life. There is no quiz at the end, don’t worry. Or is there?&lt;/p&gt;

&lt;p&gt;We will take six of the top ranking words and plot their usage over time, identifying a couple of notable dates(guess what I’m going to call this variable). First, notable dates and top words:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# did you guess right?&lt;/span&gt;
notable_dates &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;data_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;NotableDate &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;ymd&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;2013-09-16&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; ymd&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;2014-09-01&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; 
                            WhyNotable &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Moved to London&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;Started new job&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# getting top 6 words, see notes below&lt;/span&gt;
top_words &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; words_index &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; count&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Word&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; top_n&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; n&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;Word&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The most interesting thing about the last line is &lt;code&gt;.$Word&lt;/code&gt; - which is my personal favourite for extracting one column from the result of dplyr’s pipeline. As you might have seen above, &lt;code&gt;.&lt;/code&gt; has a special meaning in dplyr’s pipeline - it represents data frame of current group. Without grouping it contains the entire dataset, and we use familiar &lt;code&gt;$&lt;/code&gt; to get one column from it.&lt;/p&gt;

&lt;p&gt;Next, to the plot itself. It’s not complicated at all, most of the lines are actually for customisation purposes:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;notable_dates_plot &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; words_index &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  filter&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Word &lt;span class=&quot;o&quot;&gt;%in%&lt;/span&gt; top_words&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  ggplot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;TimeStamp&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; fill &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Word&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  geom_vline&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;xintercept &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;as.numeric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;NotableDate&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# see notes below&lt;/span&gt;
                 colour &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; WhyNotable&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
             size &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; show_guide &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
             notable_dates&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  geom_histogram&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;colour &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;gray0&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  facet_wrap&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;Word&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; scales &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;free_y&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  scale_x_datetime&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Date&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; breaks &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; date_breaks&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;6 months&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# thanks to &amp;quot;scales&amp;quot; package, we can use those amazing helpers&lt;/span&gt;
                   labels&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;date_format&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;%b, %Y&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  scale_fill_discrete&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Word&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  scale_colour_manual&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Notable dates&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; values &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;red&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;orange&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  ylab&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Number of queries&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  theme&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;axis.text.x&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;element_text&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;angle&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# see ggplot&amp;#39;s help pages for information about theme&amp;#39;s parameters&lt;/span&gt;
        legend.text&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;element_text&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;size&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
        strip.text&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;element_text&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;size&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The peculiar construct in &lt;code&gt;geom_vline&lt;/code&gt;, &lt;code&gt;xintercept = as.numeric(NotableDate)&lt;/code&gt; is required because internally time objects are represented as integers, therefore ggplot will expect xintercept to be of the same type, as the underlying scale. I find this feature(or bug) somewhat annoying, as I always forget the reason for the error message it produces.&lt;/p&gt;

&lt;p&gt;We don’t do much sophisticated processing here, instead we try to arrange the information on the plot in condensed manner, but so it still shows the underlying patterns in data.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/google-searches/top-usage.png&quot; alt=&quot;Top terms usage&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And here it is. The year between moving to London and starting a job was the year I was getting my Master’s degree.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Personal notes(the ones you can actually skip):&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Increasing usage of Python right before getting a job(my MSc project was about neural networks and all the simulations were done in Python, there was only 5 days between submission and starting the job).&lt;/li&gt;
  &lt;li&gt;Drop in Ruby usage until right before submitting the paper – it’s in this time that I wrote(and abandoned) &lt;a href=&quot;https://github.com/keynmol/octane&quot;&gt;octane&lt;/a&gt; to aid me in visualising what the hell was going on in those bloody neural networks. Before moving to London Ruby was my main go-to language and a centerpiece of my work stack.&lt;/li&gt;
  &lt;li&gt;Increased interest in London right after getting the job - more money meant more entertainment opportunities.&lt;/li&gt;
  &lt;li&gt;Interestingly similar patterns in “chords” and “lyrics” over the months spent at university. I guess there was too much drinking going on in the beginning, and then too much writing at the end.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Thanks for getting this far!&lt;/p&gt;

&lt;p&gt;The code for producing all of those plots is available on &lt;a href=&quot;https://github.com/keynmol/keynmol.github.io/tree/master/code/google-searches/&quot;&gt;blog’s github&lt;/a&gt;, just feed it your own data and it probably won’t explode(I take no responsbility, but you can &lt;a href=&quot;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#107;&amp;#101;&amp;#121;&amp;#110;&amp;#109;&amp;#111;&amp;#108;&amp;#064;&amp;#103;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&quot;&gt;email me&lt;/a&gt;)&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/data%20analysis/data-analysis-vs-google-search-history/&quot;&gt;Data Analysis vs. Google search history&lt;/a&gt; was originally published by Anton Sviridov at &lt;a href=&quot;&quot;&gt;The many shades of data&lt;/a&gt; on May 31, 2015.&lt;/p&gt;
  </content>
</entry>

</feed>
